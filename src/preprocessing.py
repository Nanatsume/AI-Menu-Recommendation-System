"""
Data Preprocessing Module for AI Menu Recommendation System
‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import pickle
import os

class DataPreprocessor:
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        self.encoders = {}
        self.scaler = StandardScaler()
        
    def load_data(self, df_customers=None, df_menu=None, df_orders=None):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏´‡∏£‡∏∑‡∏≠ DataFrame"""
        print("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        
        if df_customers is not None and df_menu is not None and df_orders is not None:
            # ‡πÉ‡∏ä‡πâ DataFrame ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤
            self.df_customers = df_customers.copy()
            self.df_menu = df_menu.copy()
            self.df_orders = df_orders.copy()
            
            print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DataFrame ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô:")
            print(f"   üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {len(self.df_customers)} ‡∏Ñ‡∏ô")
            print(f"   üçΩÔ∏è ‡πÄ‡∏°‡∏ô‡∏π: {len(self.df_menu)} ‡πÄ‡∏°‡∏ô‡∏π")
            print(f"   üìù ‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå: {len(self.df_orders)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
        else:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV
            try:
                self.df_customers = pd.read_csv(f'{self.data_dir}/customers.csv')
                self.df_menu = pd.read_csv(f'{self.data_dir}/menu.csv') 
                self.df_orders = pd.read_csv(f'{self.data_dir}/orders.csv')
                
                print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô:")
                print(f"   üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {len(self.df_customers)} ‡∏Ñ‡∏ô")
                print(f"   üçΩÔ∏è ‡πÄ‡∏°‡∏ô‡∏π: {len(self.df_menu)} ‡πÄ‡∏°‡∏ô‡∏π")
                print(f"   üìù ‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå: {len(self.df_orders)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                
            except FileNotFoundError as e:
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
                print("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå data_generation.py ‡∏Å‡πà‡∏≠‡∏ô")
                return False
            
        return True
    
    def create_user_item_matrix(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á User-Item Matrix ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Collaborative Filtering"""
        print("üî¢ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á User-Item Matrix...")
        
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô‡∏™‡∏±‡πà‡∏á‡πÄ‡∏°‡∏ô‡∏π‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á
        interaction_matrix = self.df_orders.groupby(['customer_id', 'menu_id']).size().reset_index(name='interactions')
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á pivot table
        self.user_item_matrix = interaction_matrix.pivot(
            index='customer_id', 
            columns='menu_id', 
            values='interactions'
        ).fillna(0)
        
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á User-Item Matrix ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {self.user_item_matrix.shape}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á binary matrix (1 = ‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á, 0 = ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á)
        self.binary_matrix = (self.user_item_matrix > 0).astype(int)
        
        return self.user_item_matrix, self.binary_matrix
    
    def prepare_training_data(self):
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (alias ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö create_training_data)"""
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏Å‡πà‡∏≠‡∏ô
        if not hasattr(self, 'user_features'):
            self.prepare_features()
        return self.create_training_data()
    
    def calculate_sparsity(self):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ sparsity ‡∏Ç‡∏≠‡∏á User-Item Matrix"""
        if not hasattr(self, 'user_item_matrix'):
            print("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á User-Item Matrix")
            return None
            
        total_possible_ratings = self.user_item_matrix.shape[0] * self.user_item_matrix.shape[1]
        actual_ratings = np.count_nonzero(self.user_item_matrix.values)
        sparsity = (1 - (actual_ratings / total_possible_ratings)) * 100
        
        return sparsity
    
    def prepare_features(self):
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        print("üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features...")
        
        # Encode categorical variables
        categorical_cols = ['gender', 'preferred_time']
        for col in categorical_cols:
            self.encoders[col] = LabelEncoder()
            self.df_customers[f'{col}_encoded'] = self.encoders[col].fit_transform(self.df_customers[col])
        
        # Menu features
        menu_categorical_cols = ['category']
        for col in menu_categorical_cols:
            self.encoders[f'menu_{col}'] = LabelEncoder()
            self.df_menu[f'{col}_encoded'] = self.encoders[f'menu_{col}'].fit_transform(self.df_menu[col])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á user features
        self.user_features = self.df_customers[['customer_id', 'age', 'avg_budget', 
                                               'gender_encoded', 'preferred_time_encoded']].copy()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á item features  
        self.item_features = self.df_menu[['menu_id', 'price', 'popularity', 
                                          'category_encoded']].copy()
        
        print("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
        return self.user_features, self.item_features
    
    def create_training_data(self, test_size=0.2):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
        print("üìö ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á positive samples ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á
        positive_samples = []
        for _, row in self.df_orders.iterrows():
            positive_samples.append({
                'customer_id': row['customer_id'],
                'menu_id': row['menu_id'],
                'rating': 1  # ‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á = 1
            })
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á negative samples (‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á)
        negative_samples = []
        all_customers = set(self.df_customers['customer_id'])
        all_menus = set(self.df_menu['menu_id'])
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡∏™‡∏£‡πâ‡∏≤‡∏á negative samples
        for customer_id in all_customers:
            # ‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á
            ordered_menus = set(self.df_orders[self.df_orders['customer_id'] == customer_id]['menu_id'])
            # ‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á
            not_ordered = all_menus - ordered_menus
            
            # ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å negative samples (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö positive samples)
            n_negative = len(ordered_menus)
            if len(not_ordered) >= n_negative:
                sampled_negative = np.random.choice(list(not_ordered), n_negative, replace=False)
                for menu_id in sampled_negative:
                    negative_samples.append({
                        'customer_id': customer_id,
                        'menu_id': menu_id,
                        'rating': 0  # ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á = 0
                    })
        
        # ‡∏£‡∏ß‡∏° positive ‡πÅ‡∏•‡∏∞ negative samples
        all_samples = positive_samples + negative_samples
        self.training_data = pd.DataFrame(all_samples)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° features
        self.training_data = self.training_data.merge(
            self.user_features, on='customer_id', how='left'
        ).merge(
            self.item_features, on='menu_id', how='left'
        )
        
        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train/test
        self.train_data, self.test_data = train_test_split(
            self.training_data, test_size=test_size, random_state=42, stratify=self.training_data['rating']
        )
        
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô:")
        print(f"   üìö Train: {len(self.train_data)} samples")
        print(f"   üß™ Test: {len(self.test_data)} samples")
        print(f"   ‚ûï Positive: {sum(self.training_data['rating'])} samples")
        print(f"   ‚ûñ Negative: {len(self.training_data) - sum(self.training_data['rating'])} samples")
        
        return self.train_data, self.test_data
    
    def create_user_item_mappings(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á mapping dictionaries ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á ID"""
        print("üó∫Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á ID mappings...")
        
        # User mappings
        unique_users = sorted(self.df_customers['customer_id'].unique())
        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}
        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}
        
        # Item mappings  
        unique_items = sorted(self.df_menu['menu_id'].unique())
        self.item_to_idx = {item: idx for idx, item in enumerate(unique_items)}
        self.idx_to_item = {idx: item for item, idx in self.item_to_idx.items()}
        
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á mappings ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(unique_users)} users, {len(unique_items)} items")
        
        return self.user_to_idx, self.item_to_idx
    
    def save_preprocessed_data(self, output_dir="data/processed"):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß"""
        os.makedirs(output_dir, exist_ok=True)
        print(f"üíæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô {output_dir}/...")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å DataFrames
        self.train_data.to_csv(f'{output_dir}/train_data.csv', index=False)
        self.test_data.to_csv(f'{output_dir}/test_data.csv', index=False)
        self.user_features.to_csv(f'{output_dir}/user_features.csv', index=False)
        self.item_features.to_csv(f'{output_dir}/item_features.csv', index=False)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å matrices
        np.save(f'{output_dir}/user_item_matrix.npy', self.user_item_matrix.values)
        np.save(f'{output_dir}/binary_matrix.npy', self.binary_matrix.values)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å mappings ‡πÅ‡∏•‡∏∞ encoders
        with open(f'{output_dir}/mappings.pkl', 'wb') as f:
            pickle.dump({
                'user_to_idx': self.user_to_idx,
                'item_to_idx': self.item_to_idx,
                'idx_to_user': self.idx_to_user,
                'idx_to_item': self.idx_to_item,
                'user_ids': list(self.user_item_matrix.index),
                'item_ids': list(self.user_item_matrix.columns)
            }, f)
        
        with open(f'{output_dir}/encoders.pkl', 'wb') as f:
            pickle.dump(self.encoders, f)
        
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    def get_data_summary(self):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        print("\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°:")
        print(f"   üë• ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤: {len(self.df_customers)}")
        print(f"   üçΩÔ∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏°‡∏ô‡∏π: {len(self.df_menu)}")
        print(f"   üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå: {len(self.df_orders)}")
        print(f"   üî¢ Matrix shape: {self.user_item_matrix.shape}")
        print(f"   üìö Training samples: {len(self.training_data)}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÄ‡∏°‡∏ô‡∏π
        print(f"\nüìã ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÄ‡∏°‡∏ô‡∏π:")
        category_counts = self.df_menu['category'].value_counts()
        for category, count in category_counts.items():
            print(f"   {category}: {count} ‡πÄ‡∏°‡∏ô‡∏π")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏≠‡∏≤‡∏¢‡∏∏‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
        print(f"\nüë• ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏¢‡∏∏‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤:")
        age_bins = pd.cut(self.df_customers['age'], bins=[0, 25, 35, 45, 55, 100], labels=['18-25', '26-35', '36-45', '46-55', '55+'])
        age_counts = age_bins.value_counts()
        for age_range, count in age_counts.items():
            print(f"   {age_range}: {count} ‡∏Ñ‡∏ô")
    
    def run_preprocessing(self):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ preprocessing ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if not self.load_data():
            return False
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á User-Item Matrix
        self.create_user_item_matrix()
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features
        self.prepare_features()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        self.create_training_data()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á mappings
        self.create_user_item_mappings()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        self.save_preprocessed_data()
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
        self.get_data_summary()
        
        print("\nüéâ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        return True

if __name__ == "__main__":
    # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    preprocessor = DataPreprocessor()
    preprocessor.run_preprocessing()
